{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import layer,neuron\n",
    "import torch.nn as nn\n",
    "from BNN import *\n",
    "from timm.models.layers import to_2tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1_linear = nn.Linear(in_features, hidden_features)\n",
    "        self.fc1_bn = nn.BatchNorm1d(hidden_features)\n",
    "        self.fc1_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.fc2_linear = nn.Linear(hidden_features, out_features)\n",
    "        self.fc2_bn = nn.BatchNorm1d(out_features)\n",
    "        self.fc2_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.c_hidden = hidden_features\n",
    "        self.c_output = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "        x_ = x.flatten(0, 1)\n",
    "        x = self.fc1_linear(x_)\n",
    "        x = self.fc1_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, self.c_hidden).contiguous()\n",
    "        x = self.fc1_lif(x)\n",
    "\n",
    "        x = self.fc2_linear(x.flatten(0,1))\n",
    "        x = self.fc2_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        x = self.fc2_lif(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSA(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = 0.125\n",
    "        self.q_linear = BinaryLinear(dim, dim)\n",
    "        self.q_bn = nn.BatchNorm1d(dim)\n",
    "        self.q_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.k_linear = BinaryLinear(dim, dim)\n",
    "        self.k_bn = nn.BatchNorm1d(dim)\n",
    "        self.k_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.v_linear = BinaryLinear(dim, dim)\n",
    "        self.v_bn = nn.BatchNorm1d(dim)\n",
    "        self.v_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "        self.attn_lif = neuron.LIFNode(tau=2.0, v_threshold=0.5, detach_reset=True)\n",
    "\n",
    "        self.proj_linear = BinaryLinear(dim, dim)\n",
    "        self.proj_bn = nn.BatchNorm1d(dim)\n",
    "        self.proj_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "\n",
    "        x_for_qkv = x.flatten(0, 1)  # TB, N, C\n",
    "        q_linear_out = self.q_linear(x_for_qkv)  # [TB, N, C]\n",
    "        q_linear_out = self.q_bn(q_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        q_linear_out = self.q_lif(q_linear_out)\n",
    "        q = q_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        k_linear_out = self.k_linear(x_for_qkv)\n",
    "        k_linear_out = self.k_bn(k_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        k_linear_out = self.k_lif(k_linear_out)\n",
    "        k = k_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        v_linear_out = self.v_linear(x_for_qkv)\n",
    "        v_linear_out = self.v_bn(v_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        v_linear_out = self.v_lif(v_linear_out)\n",
    "        v = v_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        x = attn @ v\n",
    "        x = x.transpose(2, 3).reshape(T, B, N, C).contiguous()\n",
    "        x = self.attn_lif(x)\n",
    "        x = x.flatten(0, 1)\n",
    "        x = self.proj_lif(self.proj_bn(self.proj_linear(x).transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = SSA(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                              attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(in_features=dim, hidden_features=mlp_hidden_dim, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(x)\n",
    "        x = x + self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPS(nn.Module):\n",
    "    def __init__(self, img_size_h=128, img_size_w=128, patch_size=4, in_channels=2, embed_dims=256):\n",
    "        super().__init__()\n",
    "        self.image_size = [img_size_h, img_size_w]\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.patch_size = patch_size\n",
    "        self.C = in_channels\n",
    "        self.H, self.W = self.image_size[0] // patch_size[0], self.image_size[1] // patch_size[1]\n",
    "        self.num_patches = self.H * self.W\n",
    "        self.proj_conv = nn.Conv2d(in_channels, embed_dims//8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn = nn.BatchNorm2d(embed_dims//8)\n",
    "        self.proj_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.proj_conv1 = nn.Conv2d(embed_dims//8, embed_dims//4, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn1 = nn.BatchNorm2d(embed_dims//4)\n",
    "        self.proj_lif1 = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.proj_conv2 = nn.Conv2d(embed_dims//4, embed_dims//2, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn2 = nn.BatchNorm2d(embed_dims//2)\n",
    "        self.proj_lif2 = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.proj_conv3 = nn.Conv2d(embed_dims//2, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn3 = nn.BatchNorm2d(embed_dims)\n",
    "        self.proj_lif3 = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.rpe_conv = nn.Conv2d(embed_dims, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.rpe_bn = nn.BatchNorm2d(embed_dims)\n",
    "        self.rpe_lif = neuron.LIFNode(tau=2.0, detach_reset=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        T, B, C, H, W = x.shape\n",
    "        x = self.proj_conv(x.flatten(0, 1)) # have some fire value\n",
    "        x = self.proj_bn(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv1(x)\n",
    "        x = self.proj_bn1(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif1(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv2(x)\n",
    "        x = self.proj_bn2(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif2(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.proj_conv3(x)\n",
    "        x = self.proj_bn3(x).reshape(T, B, -1, H//2, W//2).contiguous()\n",
    "        x = self.proj_lif3(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x_feat = x.reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_conv(x)\n",
    "        x = self.rpe_bn(x).reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_lif(x)\n",
    "        x = x + x_feat\n",
    "\n",
    "        x = x.flatten(-2).transpose(-1, -2)  # T,B,N,C\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
