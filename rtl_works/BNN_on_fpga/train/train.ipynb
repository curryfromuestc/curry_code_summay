{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from BNN import *\n",
    "from spikingjelly.activation_based import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43487784], dtype=torch.int32)\n",
      "tensor([[[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,  -629,  -374,  -127],\n",
      "         [    0,     0,     0,  ..., -1130,  -633,  -191],\n",
      "         ...,\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1113,  ...,     0,     0,     0],\n",
      "         [ -191,  -616, -1095,  ...,     0,     0,     0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#加载MNIST数据集\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='/Users/curryyang/code/curry_code_summay/AI', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/Users/curryyang/code/curry_code_summay/AI', train=False, transform=transform, download=True)\n",
    "\n",
    "#加载MNIST数据集的第一张图片\n",
    "image, label = train_dataset[0]\n",
    "#将图片用matplotlib画出来\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.squeeze().numpy())\n",
    "plt.show()\n",
    "#讲image转化为int8类型\n",
    "image = image * 255\n",
    "#print(image.int())\n",
    "\n",
    "#用一个权重全为1的卷积核对图片进行卷积\n",
    "conv1 = nn.Conv2d(1, 6, 5, 1, 0, bias=False)\n",
    "conv2 = nn.Conv2d(6, 12, 5, 1, 0, bias=False)\n",
    "conv1.weight.data.fill_(-1)\n",
    "conv2.weight.data.fill_(-1)\n",
    "output = conv1(image)\n",
    "# print(output.shape)\n",
    "# print(output.int())\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "fc = nn.Linear(192, 1,bias=False)\n",
    "fc.weight.data.fill_(1)\n",
    "output2 = pool(output)\n",
    "output3 = conv2(output2)\n",
    "output4 = pool(output3)\n",
    "output5 = output4.view(-1)\n",
    "output6 = fc(output5)\n",
    "print(output6.int())\n",
    "\n",
    "\n",
    "# print(output2.shape)\n",
    "# print(output2.int())\n",
    "#将image转化为32位有符号\n",
    "image = image.int()\n",
    "\n",
    "#按行将image转化为txt文件\n",
    "with open('/Users/curryyang/code/curry_code_summay/rtl_works/BNN_on_fpga/test_image_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image[0, i, j].item(), '032b') + '\\n')\n",
    "output_int = output.int()\n",
    "print(output_int)\n",
    "#按行将output转化为32位有符号整数的txt文件\n",
    "with open('/Users/curryyang/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output_txt.txt', 'w') as f:\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            value = output_int[0, i, j].item()\n",
    "            if value < 0:\n",
    "                value = (1 << 32) + value  # 将负数转换为32位有符号整数的二进制表示\n",
    "            f.write(format(value, '032b') + '\\n')\n",
    "output5_int = output5.int()\n",
    "#将output5转化为32位有符号整数的txt文件\n",
    "with open('/Users/curryyang/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output5_txt.txt', 'w') as f:\n",
    "    for i in range(192):\n",
    "        value = output5_int[i].item()\n",
    "        if value < 0:\n",
    "            value = (1 << 32) + value\n",
    "        f.write(format(value, '032b') + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = BinaryConv2d(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = BinaryConv2d(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = BinaryLinear(12*4*4, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = BinaryLinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = BinaryLinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        #x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): BinaryConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): BinaryConv2d(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (fc1): BinaryLinear(in_features=192, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "functional.set_step_mode(net, 'm')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(128, 1, 28, 28)\n",
    "y = net(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.306\n",
      "[1,   101] loss: 0.563\n",
      "[1,   201] loss: 0.425\n",
      "[1,   301] loss: 0.430\n",
      "[1,   401] loss: 0.284\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[2,     1] loss: 0.212\n",
      "[2,   101] loss: 0.231\n",
      "[2,   201] loss: 0.222\n",
      "[2,   301] loss: 0.215\n",
      "[2,   401] loss: 0.304\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[3,     1] loss: 0.331\n",
      "[3,   101] loss: 0.204\n",
      "[3,   201] loss: 0.202\n",
      "[3,   301] loss: 0.162\n",
      "[3,   401] loss: 0.197\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[4,     1] loss: 0.100\n",
      "[4,   101] loss: 0.145\n",
      "[4,   201] loss: 0.194\n",
      "[4,   301] loss: 0.230\n",
      "[4,   401] loss: 0.166\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[5,     1] loss: 0.138\n",
      "[5,   101] loss: 0.111\n",
      "[5,   201] loss: 0.178\n",
      "[5,   301] loss: 0.110\n",
      "[5,   401] loss: 0.124\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[6,     1] loss: 0.060\n",
      "[6,   101] loss: 0.197\n",
      "[6,   201] loss: 0.175\n",
      "[6,   301] loss: 0.188\n",
      "[6,   401] loss: 0.333\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[7,     1] loss: 0.217\n",
      "[7,   101] loss: 0.125\n",
      "[7,   201] loss: 0.226\n",
      "[7,   301] loss: 0.129\n",
      "[7,   401] loss: 0.088\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[8,     1] loss: 0.102\n",
      "[8,   101] loss: 0.057\n",
      "[8,   201] loss: 0.114\n",
      "[8,   301] loss: 0.112\n",
      "[8,   401] loss: 0.106\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "[9,     1] loss: 0.090\n",
      "[9,   101] loss: 0.133\n",
      "[9,   201] loss: 0.113\n",
      "[9,   301] loss: 0.096\n",
      "[9,   401] loss: 0.081\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[10,     1] loss: 0.231\n",
      "[10,   101] loss: 0.141\n",
      "[10,   201] loss: 0.150\n",
      "[10,   301] loss: 0.140\n",
      "[10,   401] loss: 0.111\n",
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "np.int = int\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "EPOCH = 10\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    for i ,data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        functional.reset_net(net)\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "torch.save(net.state_dict(), 'weight/lenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_Bconvd(BinaryConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(scale_Bconvd, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "    def forward(self, x):\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        scaling_factor = torch.mean(torch.mean(torch.mean(torch.mean(abs(w),dim=3,keepdim=True),dim=2,keepdim=True),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "    \n",
    "        return F.conv2d(x, bw, self.bias, self.stride,\n",
    "                    self.padding, self.dilation, self.groups)\n",
    "class scale_Blinear(BinaryLinear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(scale_Blinear, self).__init__(in_features, out_features, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        # print(w.shape)\n",
    "        scaling_factor = torch.mean(torch.mean(abs(w),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "        \n",
    "        return F.linear(x, bw, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = scale_Bconvd(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = scale_Blinear(12*4*4, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = scale_Blinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = scale_Blinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        #x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_leNet(\n",
      "  (conv1): scale_Bconvd(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): scale_Bconvd(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (fc1): scale_Blinear(in_features=192, out_features=10, bias=False)\n",
      ")\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65151/3637794216.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('weight/lenet.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "tensor([[[[0.2125]]]], device='cuda:0')\n",
      "tensor([[[[0.1393]]]], device='cuda:0')\n",
      "tensor([[0.1572]], device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "net = scale_leNet()\n",
    "functional.set_step_mode(net, 'm')\n",
    "print(net)\n",
    "#加载权重\n",
    "net.load_state_dict(torch.load('weight/lenet.pth'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
