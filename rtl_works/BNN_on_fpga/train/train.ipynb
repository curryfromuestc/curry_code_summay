{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from BNN import *\n",
    "from spikingjelly.activation_based import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[   0,    0,    0,    0,   21,   57,  316,  481,  758,  869,  795,\n",
      "           374],\n",
      "         [   0,   49,  606, 1360, 1993, 2405, 2844, 2813, 2546, 2308, 1726,\n",
      "           672],\n",
      "         [   0,   67, 1332, 2952, 4232, 4267, 4378, 3889, 3231, 2308, 1726,\n",
      "           672],\n",
      "         [   0,   67, 1346, 3121, 4723, 4726, 4435, 3416, 2602, 1439,  931,\n",
      "           298],\n",
      "         [   0,   18,  740, 1911, 3787, 3645, 2946, 1148,  685,    0,    0,\n",
      "             0],\n",
      "         [   0,    0,   14,  319, 1905, 2840, 3038, 2343, 1189,  202,    0,\n",
      "             0],\n",
      "         [   0,    0,    0,   11,  811, 2006, 3102, 3387, 2789, 1208,   64,\n",
      "             0],\n",
      "         [   0,    0,    0,    0,  187, 1092, 3095, 4638, 4119, 2077,   66,\n",
      "             0],\n",
      "         [   0,    0,   89,  693, 1837, 3149, 3997, 4554, 3968, 1978,   66,\n",
      "             0],\n",
      "         [ 227,  895, 1907, 3098, 3938, 4181, 4089, 3764, 2451,  972,    2,\n",
      "             0],\n",
      "         [ 616, 1790, 3013, 3846, 4034, 3913, 2952, 1661,  615,   78,    0,\n",
      "             0],\n",
      "         [ 616, 1790, 2924, 3153, 2862, 1823,  681,   89,    0,    0,    0,\n",
      "             0]]], dtype=torch.int32)\n",
      "tensor([[[28325, 43425, 58143, 65866, 66344, 58512, 48590, 35687],\n",
      "         [30542, 48425, 65865, 75436, 76026, 65643, 52143, 36144],\n",
      "         [27356, 44840, 62587, 73338, 75520, 65219, 50456, 33527],\n",
      "         [18960, 33269, 49800, 62632, 68654, 62167, 48919, 32601],\n",
      "         [12322, 25054, 41214, 56441, 66257, 63195, 50659, 34481],\n",
      "         [15931, 28972, 45398, 62074, 72469, 70228, 57158, 39837],\n",
      "         [26992, 40490, 55040, 68035, 74329, 69835, 55692, 38457],\n",
      "         [37515, 50214, 60553, 67326, 67689, 59936, 45912, 31098]]],\n",
      "       dtype=torch.int32)\n",
      "tensor([[[48425, 75436, 76026, 52143],\n",
      "         [44840, 73338, 75520, 50456],\n",
      "         [28972, 62074, 72469, 57158],\n",
      "         [50214, 68035, 74329, 55692]]], dtype=torch.int32)\n",
      "tensor([[[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,    0,    3,   21,   39,\n",
      "            57,  183,  316,  473,  481,  629,  758,  869,  821,  795,  629,\n",
      "           374,  127],\n",
      "         [   0,    0,    0,    0,   30,   66,  160,  314,  487,  728,  963,\n",
      "          1140, 1365, 1581, 1710, 1637, 1785, 1903, 1956, 1747, 1549, 1130,\n",
      "           633,  191],\n",
      "         [   0,    0,    0,   49,  317,  606,  953, 1360, 1737, 1993, 2228,\n",
      "          2405, 2630, 2844, 2813, 2569, 2546, 2467, 2308, 2006, 1726, 1225,\n",
      "           672,  191],\n",
      "         [   0,    0,    0,   67,  554, 1096, 1696, 2356, 2968, 3258, 3438,\n",
      "          3544, 3763, 3965, 3681, 3239, 3034, 2708, 2308, 2006, 1726, 1225,\n",
      "           672,  191],\n",
      "         [   0,    0,    0,   67,  634, 1332, 2039, 2952, 3817, 4232, 4267,\n",
      "          4266, 4275, 4378, 3889, 3436, 3231, 2862, 2308, 2006, 1726, 1225,\n",
      "           672,  191],\n",
      "         [   0,    0,    0,   67,  634, 1346, 2054, 3121, 4236, 4723, 4726,\n",
      "          4706, 4435, 4152, 3416, 2955, 2602, 2104, 1439, 1185,  931,  596,\n",
      "           298,   64],\n",
      "         [   0,    0,    0,   67,  604, 1280, 1894, 2946, 4144, 4598, 4386,\n",
      "          4207, 3698, 3079, 2181, 1799, 1446,  959,  352,  259,  177,   95,\n",
      "            39,    0],\n",
      "         [   0,    0,    0,   18,  317,  740, 1101, 1911, 3095, 3787, 3645,\n",
      "          3466, 2946, 2139, 1148,  867,  685,  395,    0,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,   80,  250,  358,  915, 1899, 2798, 2936,\n",
      "          2988, 2582, 1753,  774,  466,  306,  155,    0,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,   14,   15,  319, 1050, 1905, 2428,\n",
      "          2840, 2897, 2286, 1456,  919,  506,  145,   25,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,  150,  628, 1393, 1975,\n",
      "          2574, 3038, 2933, 2343, 1788, 1189,  575,  202,   27,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,   11,  236,  811, 1391,\n",
      "          2006, 2702, 3102, 2955, 2589, 1974, 1267,  642,  214,    0,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,    0,   35,  357,  867,\n",
      "          1482, 2189, 3028, 3387, 3340, 2789, 2082, 1208,  527,   64,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,    0,    0,   81,  412,\n",
      "           997, 1779, 2905, 3758, 4097, 3578, 2796, 1670,  736,   66,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,    0,    0,   39,  187,  507,\n",
      "          1092, 1874, 3095, 4106, 4638, 4119, 3337, 2077,  918,   66,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,    0,    0,   24,  138,  398,  799, 1327,\n",
      "          1955, 2623, 3571, 4257, 4554, 3968, 3186, 1978,  891,   66,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,    0,    0,   23,   89,  326,  693, 1206, 1837, 2552,\n",
      "          3149, 3552, 3997, 4177, 4034, 3266, 2496, 1538,  704,   66,    0,\n",
      "             0,    0],\n",
      "         [   0,    0,   18,  189,  431,  750, 1240, 1842, 2437, 3044, 3586,\n",
      "          3939, 4089, 4032, 3764, 3292, 2451, 1681,  972,  391,    2,    0,\n",
      "             0,    0],\n",
      "         [  55,  227,  471,  895, 1390, 1907, 2478, 3098, 3573, 3938, 4181,\n",
      "          4151, 3874, 3431, 2899, 2266, 1553,  966,  510,  182,    0,    0,\n",
      "             0,    0],\n",
      "         [ 191,  616, 1113, 1790, 2497, 3013, 3463, 3846, 4029, 4034, 3913,\n",
      "          3498, 2952, 2295, 1661, 1075,  615,  281,   78,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [ 191,  616, 1113, 1790, 2497, 3013, 3439, 3708, 3670, 3422, 3048,\n",
      "          2404, 1719, 1082,  623,  290,   83,    2,    0,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [ 191,  616, 1113, 1790, 2474, 2924, 3137, 3153, 2862, 2384, 1823,\n",
      "          1194,  681,  295,   89,    9,    0,    0,    0,    0,    0,    0,\n",
      "             0,    0],\n",
      "         [ 191,  616, 1095, 1601, 2066, 2263, 2223, 2004, 1631, 1177,  789,\n",
      "           404,  144,   11,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "             0,    0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#加载MNIST数据集\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/curry/code', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/curry/code', train=False, transform=transform, download=True)\n",
    "\n",
    "#加载MNIST数据集的第一张图片\n",
    "image, label = train_dataset[0]\n",
    "#将图片用matplotlib画出来\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.squeeze().numpy())\n",
    "plt.show()\n",
    "#讲image转化为int8类型\n",
    "image = image * 255\n",
    "#print(image.int())\n",
    "\n",
    "#用一个权重全为1的卷积核对图片进行卷积\n",
    "conv1 = nn.Conv2d(1, 1, 5, 1, 0, bias=False)\n",
    "conv2 = nn.Conv2d(1, 1, 5, 1, 0, bias=False)\n",
    "relu1 = nn.ReLU()\n",
    "conv1.weight.data.fill_(1)\n",
    "conv2.weight.data.fill_(1)\n",
    "output = conv1(image)\n",
    "# print(output.shape)\n",
    "# print(output.int())\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "fc = nn.Linear(192, 1,bias=False)\n",
    "fc.weight.data.fill_(1)\n",
    "output1 = relu1(output)\n",
    "output2 = pool(output1)\n",
    "print(output2.int())\n",
    "output3 = conv2(output2)\n",
    "print(output3.int())\n",
    "output3 = relu1(output3)\n",
    "output4 = pool(output3)\n",
    "print(output4.int())\n",
    "# output5 = output4.view(-1)\n",
    "# output6 = fc(output5)\n",
    "# print(output6.int())\n",
    "\n",
    "\n",
    "# print(output2.shape)\n",
    "# print(output2.int())\n",
    "#将image转化为32位有符号\n",
    "image_int = image.int()\n",
    "\n",
    "#按行将image转化为txt文件\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_image_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_int[0, i, j].item(), '032b') + '\\n')\n",
    "output_int = output.int()\n",
    "print(output_int)\n",
    "#按行将output转化为32位有符号整数的txt文件\n",
    "# with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output_txt.txt', 'w') as f:\n",
    "#     for i in range(24):\n",
    "#         for j in range(24):\n",
    "#             value = output_int[0, i, j].item()\n",
    "#             if value < 0:\n",
    "#                 value = (1 << 32) + value  # 将负数转换为32位有符号整数的二进制表示\n",
    "#             f.write(format(value, '032b') + '\\n')\n",
    "# output5_int = output5.int()\n",
    "# #将output5转化为32位有符号整数的txt文件\n",
    "# with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output5_txt.txt', 'w') as f:\n",
    "#     for i in range(192):\n",
    "#         value = output5_int[i].item()\n",
    "#         if value < 0:\n",
    "#             value = (1 << 32) + value\n",
    "#         f.write(format(value, '032b') + '\\n')\n",
    "#将output2转化为32位有符号整数的txt文件\n",
    "output2_int = output2.int()\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output2_txt.txt', 'w') as f:\n",
    "    for i in range(12):\n",
    "        for j in range(12):\n",
    "            value = output2_int[0, i, j].item()\n",
    "            if value < 0:\n",
    "                value = (1 << 32) + value\n",
    "            f.write(format(value, '032b') + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = BinaryConv2d(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = BinaryConv2d(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = BinaryLinear(12*4*4, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = BinaryLinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = BinaryLinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool2(x)\n",
    "        #print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.int())\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): BinaryConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): BinaryConv2d(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (fc1): BinaryLinear(in_features=192, out_features=10, bias=False)\n",
      ")\n",
      "tensor([[  1,  -2,  19, -13, -13, -16,   0, -21,  16,   8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)\n",
    "#将网络的权重初始化为-1\n",
    "# for m in net.modules():\n",
    "#     if isinstance(m, BinaryConv2d) or isinstance(m, BinaryLinear):\n",
    "#         m.weight.data.fill_(1)\n",
    "#加载权重\n",
    "#net.load_state_dict(torch.load('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/train/weight/lenet_binary.pth'))\n",
    "#将图片转化为网络的输入\n",
    "image = image.unsqueeze(0)\n",
    "output = net(image)\n",
    "print(output.int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(128, 1, 28, 28)\n",
    "y = net(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.297\n",
      "[1,   101] loss: 0.460\n",
      "[1,   201] loss: 0.515\n",
      "[1,   301] loss: 0.424\n",
      "[1,   401] loss: 0.395\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "[2,     1] loss: 0.282\n",
      "[2,   101] loss: 0.245\n",
      "[2,   201] loss: 0.369\n",
      "[2,   301] loss: 0.222\n",
      "[2,   401] loss: 0.139\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[3,     1] loss: 0.160\n",
      "[3,   101] loss: 0.170\n",
      "[3,   201] loss: 0.176\n",
      "[3,   301] loss: 0.151\n",
      "[3,   401] loss: 0.057\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[4,     1] loss: 0.214\n",
      "[4,   101] loss: 0.152\n",
      "[4,   201] loss: 0.177\n",
      "[4,   301] loss: 0.166\n",
      "[4,   401] loss: 0.121\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[5,     1] loss: 0.234\n",
      "[5,   101] loss: 0.191\n",
      "[5,   201] loss: 0.188\n",
      "[5,   301] loss: 0.305\n",
      "[5,   401] loss: 0.138\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "[6,     1] loss: 0.131\n",
      "[6,   101] loss: 0.168\n",
      "[6,   201] loss: 0.213\n",
      "[6,   301] loss: 0.194\n",
      "[6,   401] loss: 0.092\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "[7,     1] loss: 0.117\n",
      "[7,   101] loss: 0.237\n",
      "[7,   201] loss: 0.200\n",
      "[7,   301] loss: 0.057\n",
      "[7,   401] loss: 0.151\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "[8,     1] loss: 0.083\n",
      "[8,   101] loss: 0.128\n",
      "[8,   201] loss: 0.108\n",
      "[8,   301] loss: 0.138\n",
      "[8,   401] loss: 0.235\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[9,     1] loss: 0.117\n",
      "[9,   101] loss: 0.054\n",
      "[9,   201] loss: 0.076\n",
      "[9,   301] loss: 0.213\n",
      "[9,   401] loss: 0.106\n",
      "Accuracy of the network on the 10000 test images: 95 %\n",
      "[10,     1] loss: 0.125\n",
      "[10,   101] loss: 0.078\n",
      "[10,   201] loss: 0.130\n",
      "[10,   301] loss: 0.176\n",
      "[10,   401] loss: 0.102\n",
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "np.int = int\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "EPOCH = 10\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    for i ,data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        functional.reset_net(net)\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "torch.save(net.state_dict(), 'weight/lenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_Bconvd(BinaryConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(scale_Bconvd, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "    def forward(self, x):\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        scaling_factor = torch.mean(torch.mean(torch.mean(torch.mean(abs(w),dim=3,keepdim=True),dim=2,keepdim=True),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "    \n",
    "        return F.conv2d(x, bw, self.bias, self.stride,\n",
    "                    self.padding, self.dilation, self.groups)\n",
    "class scale_Blinear(BinaryLinear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(scale_Blinear, self).__init__(in_features, out_features, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        # print(w.shape)\n",
    "        scaling_factor = torch.mean(torch.mean(abs(w),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "        \n",
    "        return F.linear(x, bw, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = scale_Bconvd(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = scale_Blinear(12*4*4, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = scale_Blinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = scale_Blinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_leNet(\n",
      "  (conv1): scale_Bconvd(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): scale_Bconvd(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (fc1): scale_Blinear(in_features=192, out_features=10, bias=False)\n",
      ")\n",
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "net = scale_leNet()\n",
    "functional.set_step_mode(net, 'm')\n",
    "print(net)\n",
    "#加载权重\n",
    "device = torch.device('cuda:0')\n",
    "net.load_state_dict(torch.load('weight/lenet.pth',weights_only=True))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "#将权重加载，二值化，保存为另外一个pth文件\n",
    "net.load_state_dict(torch.load('weight/lenet.pth',weights_only=True))\n",
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        param.data = BinaryWeight.apply(param.data)\n",
    "torch.save(net.state_dict(), 'weight/lenet_binary.pth')\n",
    "#加载二值化后的权重\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ..., -1., -1.,  1.],\n",
      "        ...,\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ...,  1., -1., -1.]], device='cuda:0')\n",
      "torch.Size([10, 192])\n",
      "torch.Size([1920])\n",
      "tensor([ 1,  1,  1,  ...,  1, -1, -1], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#将网络第一层的权重导出\n",
    "conv1_weight = net.conv1.weight.data\n",
    "#print(conv1_weight)\n",
    "conv1_weight = conv1_weight.view(-1)\n",
    "#print(conv1_weight.shape)\n",
    "conv1_weight_int = conv1_weight.int()\n",
    "#print(conv1_weight_int)\n",
    "#将第一层的权重导出为txt文件\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_conv1_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv1_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第二层的权重导出\n",
    "conv2_weight = net.conv2.weight.data\n",
    "#print(conv2_weight.shape)\n",
    "#print(conv2_weight)\n",
    "conv2_weight = conv2_weight.view(-1)\n",
    "#print(conv2_weight.shape)\n",
    "conv2_weight_int = conv2_weight.int()\n",
    "#print(conv2_weight_int)\n",
    "#将第二层的权重导出为txt文件\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_conv2_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv2_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第三层的权重导出\n",
    "fc1_weight = net.fc1.weight.data\n",
    "print(fc1_weight)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight = fc1_weight.view(-1)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight_int = fc1_weight.int()\n",
    "print(fc1_weight_int)\n",
    "#将第三层的权重导出为txt文件\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_fc1_weight_txt.txt', 'w') as f:\n",
    "    for weight in fc1_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1., -1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1.,  1.,  1.]]]], requires_grad=True)\n",
      "tensor([[[[   0,    0,    0,    0,    0,    0,    0,   79,  245,   73,  629,\n",
      "            374],\n",
      "          [   0,    0,    0,   40,  475,  887, 1330, 1875, 1712, 1800, 1726,\n",
      "            672],\n",
      "          [   0,   31,  294, 1406, 1860, 2200, 2285, 2417, 1944,  986,  136,\n",
      "              0],\n",
      "          [   0,   67,  316,  410,  189,  652,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,  529,  356,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,  976, 1434, 1135,  202,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0, 1117, 1664, 1158,   64,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0,  394, 1644, 1266,   66,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,  319, 1649, 2213, 1789,  896,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,  389, 1550, 2168, 2181, 1853,   58,    0,    0,    0,\n",
      "              0],\n",
      "          [ 110, 1248, 1767, 2197, 1903,  239,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [ 506,  623,  246,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "              0]],\n",
      "\n",
      "         [[   0,    0,    0,    0,    0,    0,    8,  157,  196,   57,  375,\n",
      "            374],\n",
      "          [   0,    0,    2,  348,  909, 1079, 1258, 1543, 1166, 1214,  827,\n",
      "            139],\n",
      "          [   0,   67,  960, 1435, 1474, 1492, 1407, 1073,  590,   84,    0,\n",
      "              0],\n",
      "          [   0,   67,  684,  804,    2,    0,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,   18,  281,  199,  299,    0,    0,   70,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,   14,  289,  434,    0,    0,  361,  281,  152,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,   11,  339,  153,    6,   59,   97,  292,   64,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,   81,  200,  897,  812,  218,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,   55,  825, 1849, 2057, 1565,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,   45,  895, 1668, 1909, 1844,  785,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [ 616, 1644, 1811, 1767,  929,    0,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [ 506,  659,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "              0]],\n",
      "\n",
      "         [[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,  222, 1035,\n",
      "            594],\n",
      "          [   0,    0,    0,    0,    0,  472,  587, 1946, 1619, 1156, 1598,\n",
      "            672],\n",
      "          [   0,    0,    0,  120,  419, 1641, 1287, 1997, 1588,  667,  803,\n",
      "            298],\n",
      "          [   0,    0,    0,    0,    0, 1654,  976,  867,  685,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,  782,  707,  279,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,   66,  622,  633,  731,   76,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0,   57, 1835, 1213,   66,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0, 1034, 2624, 1822,   66,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,  825, 1829, 1834, 2033,  972,    2,\n",
      "              0],\n",
      "          [   0,    0,  623,  980, 1732, 1880, 1760, 1103,  615,   78,    0,\n",
      "              0],\n",
      "          [   0,  137,  981, 1357, 1552, 1273,  663,   89,    0,    0,    0,\n",
      "              0]],\n",
      "\n",
      "         [[   0,    0,    0,    0,   21,   51,  244,  401,  136,  467,    0,\n",
      "              0],\n",
      "          [   0,   49,  546,  723,  462,  425,  405,  102,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,   67,  396,  260,    0,    0,    0,    0,    0,    0,  517,\n",
      "            466],\n",
      "          [   0,   31,    0,    0,   84,    0,    0,  429,  688,  921,  741,\n",
      "            298],\n",
      "          [   0,   18,  240,  385,  435,   19,  513,  610,  395,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,   14,  128,  156,    0,    3,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,   11,  195,  135,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,  187,  890,  930,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,   89,  599,  674,  585,    0,    0,    0,  336,   66,\n",
      "              0],\n",
      "          [ 227,  749,  668,  636,    0,    0,    0,  622,  829,  510,    2,\n",
      "              0],\n",
      "          [ 506,  623,    0,    0,    0,  522,  882,  921,  611,   78,    0,\n",
      "              0],\n",
      "          [   0,    0,  557, 1014, 1065,  874,  659,   89,    0,    0,    0,\n",
      "              0]],\n",
      "\n",
      "         [[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0,  199,  833, 1154,  866,\n",
      "            204],\n",
      "          [   0,   67,  728, 1156,  839,  684,  896,  719,  830,  786,  859,\n",
      "            594],\n",
      "          [   0,    0,  106,  637,  746,  150,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,   20,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,  314, 1040,   85,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0, 1196, 1279,  705,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,    0,    0,    0,  634,  353,   62,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0,  149,  316,  221,  112,  314,   66,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,  124,  241,  321,    0,    0,   48,    0,\n",
      "              0],\n",
      "          [ 616, 1412, 1363,  879,  377,    0,    0,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [ 162,  171,  194,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "              0]],\n",
      "\n",
      "         [[   0,    0,    0,    0,   21,   33,  208,  149,   84,  135,    0,\n",
      "              0],\n",
      "          [   0,   49,  508,  379,  403,  573,  748,  717,  487,  942,   24,\n",
      "              0],\n",
      "          [   0,   67, 1260, 1593, 1305,  882, 1144, 1067,    0,  952,  944,\n",
      "            204],\n",
      "          [   0,    0,  768, 1738, 2248, 1472, 1146, 1573,  394,  893,  767,\n",
      "            220],\n",
      "          [   0,    0,    0,  899, 2507, 2564,    0,  982,  599,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,   13, 1345, 2482, 2016,    0,    0,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,    0, 1686, 2536, 2395,   81,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,    0,    0,  187,  339, 1809, 2568, 1557,    0,    0,\n",
      "              0],\n",
      "          [   0,    0,   89,  515,  773, 1065,  905, 1136, 1398,   12,   62,\n",
      "              0],\n",
      "          [ 227,  441,  605,  964, 1050,  816,  638,  820,  881,  354,    2,\n",
      "              0],\n",
      "          [ 616, 1338, 1287, 1007,  806,  698,  811,  821,  453,   78,    0,\n",
      "              0],\n",
      "          [ 272,  670,  981,  978,  941,  861,  415,   89,    0,    0,    0,\n",
      "              0]]]], dtype=torch.int32)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1., -1., -1.,  1.],\n",
      "          [-1., -1.,  1., -1.,  1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [ 1.,  1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1., -1.],\n",
      "          [ 1.,  1., -1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1.,  1., -1.,  1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1., -1., -1.,  1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1., -1.],\n",
      "          [-1.,  1., -1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1., -1., -1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1.,  1., -1., -1.,  1.]],\n",
      "\n",
      "         [[ 1., -1., -1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1., -1.,  1.],\n",
      "          [ 1., -1., -1.,  1.,  1.],\n",
      "          [ 1., -1., -1.,  1.,  1.],\n",
      "          [ 1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1., -1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  1.,  1.],\n",
      "          [-1., -1., -1.,  1., -1.],\n",
      "          [-1., -1., -1.,  1.,  1.],\n",
      "          [-1., -1., -1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.,  1., -1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1.,  1.,  1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1., -1., -1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1.,  1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1.,  1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [-1.,  1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1., -1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1.,  1.],\n",
      "          [-1.,  1., -1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1., -1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1., -1.,  1., -1.,  1.],\n",
      "          [-1., -1., -1., -1.,  1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [ 1., -1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1., -1., -1.,  1.],\n",
      "          [ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1.],\n",
      "          [-1.,  1.,  1., -1., -1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1., -1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1., -1., -1., -1., -1.],\n",
      "          [ 1.,  1., -1., -1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.,  1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1., -1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1.],\n",
      "          [-1., -1., -1., -1.,  1.],\n",
      "          [-1., -1., -1., -1., -1.]]]], requires_grad=True)\n",
      "tensor([[[[  2725,   1597,  -6894, -11001, -10972,  -8441,  -1208,    820],\n",
      "          [  1008,   6654,   2989,   4241,     99,  -2269,   8128,  17356],\n",
      "          [  -167,  13935,  16025,   7174,   3032, -12581, -15282,   -408],\n",
      "          [ -3023,   5814,  16190,  11842,   7087,  -9093, -28395, -20068],\n",
      "          [ -8031,  -7586,   1019,      1,   -442,   2158,    251,  -9298],\n",
      "          [-11323, -17918, -15966,  -6931,    263,  -1147,   2772,   -295],\n",
      "          [-23309, -23291, -23331, -14467,  -1684,  -7176,  -9618,   -374],\n",
      "          [-12255, -17007, -20372, -18343,  -7205,   4357,   5115,   4544]],\n",
      "\n",
      "         [[-21189, -29113, -27850, -33557, -34498, -34501, -28600, -25266],\n",
      "          [-17078, -29568, -26629, -12889,  -7589,  -9615,  -6798,  -5956],\n",
      "          [ 10621,  -1409,  -7479,  -3764,  11692,  10563,   4918,  -3382],\n",
      "          [  7255,   2280, -13660, -24750, -12857,    897,  10821,  11628],\n",
      "          [  3363,   6984,   5441,  -9525, -26232, -19164,  -6507,   3858],\n",
      "          [  5007,  13010,  25040,  22887,  -2779, -22203, -22470, -13607],\n",
      "          [ 16859,  17375,  11829,   7903,  -5098, -19246, -29468, -23762],\n",
      "          [  1749,  -8431, -17722, -19023, -14009,  -9875, -12613, -18288]],\n",
      "\n",
      "         [[  2087,   2721,  -5166, -10561, -19392, -22281, -20372, -15878],\n",
      "          [   530,   -604,  -9669, -18301, -26757, -31307, -22594, -13156],\n",
      "          [ -1853,  -1201,  -7969, -13084, -22452, -28991, -20368,  -6690],\n",
      "          [  1813,   5420,   1968, -12834, -16789, -16305, -13873, -13504],\n",
      "          [   563,   6916,  -2409, -12147, -11182, -13508, -12361, -17890],\n",
      "          [ -2751,   -284,   1332,  -4737,  -8777, -20783, -31756, -26777],\n",
      "          [ -2049,   -113,   5025,   2773, -10452, -29522, -37126, -22760],\n",
      "          [ -3789,  -9787, -10210, -10005, -14145, -19979, -22509, -13434]],\n",
      "\n",
      "         [[-16133, -19269, -22356, -26377, -29350, -33575, -30604, -30706],\n",
      "          [-17416, -25500, -27409, -23573, -19215, -19221, -14690, -10252],\n",
      "          [ -3165, -12063, -13745,  -2440,  12002,  18595,  13400,   5760],\n",
      "          [  1463,  -6730, -12092, -10118,   3623,  13363,  16935,   7386],\n",
      "          [  6137,   6378,  -5317, -14703, -24652, -20856,  -3649,   2962],\n",
      "          [  8371,   1178,  -7610, -17423, -24741, -23471, -15334,  -2393],\n",
      "          [ -2571, -10897, -14193, -12857, -19586, -21742, -15876,  -5726],\n",
      "          [-11237,  -9397, -15250, -24295, -29479, -28571, -14803,   1684]],\n",
      "\n",
      "         [[ -5097,  -3517,   -236,    737,   5846,  14275,  17406,  17626],\n",
      "          [  7378,   5402,   1429,   2497,     47,   3509,   4672,   7052],\n",
      "          [  2047,     51, -11155, -16654, -22554, -22767, -22182, -11588],\n",
      "          [ -1575,  -1092, -10448, -16612, -28153, -23899, -22635, -22830],\n",
      "          [ -4635,  -5680, -13723, -22843, -25736, -21050,  -3795,  -7992],\n",
      "          [-11851, -19976, -31926, -30493, -26849, -13283,  -4832,  -1887],\n",
      "          [-30391, -33949, -31029, -16427,  -1876,    700,  -1174,  -6388],\n",
      "          [-22779, -13401,    958,  13229,  13905,   3735,  -3657,  -8516]],\n",
      "\n",
      "         [[ 10775,  14677,  19352,  14895,   5056,  -5847, -16782, -24304],\n",
      "          [  3424,  -4076, -11487, -16845, -29817, -37863, -43130, -37888],\n",
      "          [-13491, -23821, -30483, -33658, -29580, -26925, -21126, -16856],\n",
      "          [-10349, -13968, -17986, -20618, -18779,  -5913,   -101,  -2834],\n",
      "          [ -6039, -14960, -17217, -17597, -13004,  -2390,  -4405,  -7404],\n",
      "          [ -7907, -17670, -20436, -14687,  -5469,  -1925, -10956, -24003],\n",
      "          [ -1949,   3555,   4427,   3219,  -1700, -18434, -34076, -30516],\n",
      "          [ 14211,  21725,  20178,  -2981, -32045, -45311, -40257, -19260]],\n",
      "\n",
      "         [[-10765, -17317, -26622, -26081, -11658, -18281, -12146,    532],\n",
      "          [ -7916,  -9408, -12195, -12823,   -255,  17111,   7556,   4430],\n",
      "          [ -5395, -13153, -13843, -24912, -17190,   7187,  16308,   7940],\n",
      "          [ -7187, -15626, -21796, -22468, -21577,  -9181,  12135,  20866],\n",
      "          [ -5673, -16082, -15441, -10497,  -4612,  -7960,  -9661,   1306],\n",
      "          [ -6591,  -4822,  -1870,  -5163, -11521, -20495, -20804, -13733],\n",
      "          [  7191,   9683,  -4583, -24361, -41978, -34588, -22214,  -8006],\n",
      "          [-11459, -19769, -26698, -27109, -18829,  -8411,  -2007,  -1450]],\n",
      "\n",
      "         [[ 10673,  16093,  19238,  13821,   1682, -11607, -19388, -21828],\n",
      "          [-16120, -21426, -23245, -35219, -41921, -52711, -48370, -35586],\n",
      "          [-15341, -21665, -21627, -20224, -14580, -15603, -14820, -12194],\n",
      "          [ -4905,  -9606,  -8326,   -558,   5127,  12043,  12307,   5564],\n",
      "          [ -5365,  -7350, -14135, -18827, -13842,  -5760,   -517,   -426],\n",
      "          [ -5337,  -6244,  -8804, -11895, -17577, -19399, -16248, -10707],\n",
      "          [  -733,  -2461,   2445,   5353,   1772,  -5688, -16146, -20064],\n",
      "          [ 14651,  13629,   3922,  -7181, -19763, -25889, -25809, -19568]],\n",
      "\n",
      "         [[ -5277,  -5627,  -1458,  -8639, -12300,  -4027,  -3518,  -3358],\n",
      "          [ -7564, -15058, -13169, -12379, -24897, -20181, -14064, -14188],\n",
      "          [   345, -12285, -20047, -14600, -24050, -28905, -28966, -12900],\n",
      "          [  4053,  -2328, -15112, -15960, -10733,  -1451,  -3857,  -4190],\n",
      "          [  4191,   4908,  -8973, -21479, -21096,   6118,  20675,  12008],\n",
      "          [   683,   7178,   3882,  -9473, -26045, -18861,   1032,  13855],\n",
      "          [   -29,  -1469,   -281,    715,  -9904, -21698, -14256,  -4494],\n",
      "          [ -7965, -12705, -11028,  -2907,   -917, -15611, -19519, -10024]],\n",
      "\n",
      "         [[-19363, -22129, -19616, -20049,  -9498,    949,  11824,  15850],\n",
      "          [ -4630,  -3526,   5563,  11021,  17499,  19773,  22526,  15050],\n",
      "          [  -869,  -6625,  -5685,  -5338,  -5920,  -4929,  -7308,  -6164],\n",
      "          [ -8075, -16184, -18520, -16832, -12837, -17915, -17575, -21104],\n",
      "          [ -8869, -20584, -28349, -23385, -14050,  -9230,  -4463, -15212],\n",
      "          [-15645, -26028, -34978, -33019, -28721, -21193,  -9978,  -1511],\n",
      "          [-29127, -37293, -45749, -49315, -32066,  -9174,   7452,   8554],\n",
      "          [-40579, -43859, -35494, -16301,  -2831,  12445,  19361,  15134]],\n",
      "\n",
      "         [[ 11871,  16583,  13252,  12247,  13098,  21707,  14012,  11390],\n",
      "          [ 13172,  15610,   4777,  -2595,  -5599,    353,     66,   -616],\n",
      "          [ -2165,   4011,   5203,  -5952, -15264, -23353, -18450, -10208],\n",
      "          [ -6801,  -4138,   5188,   1446,  -3995, -18409, -33747, -21796],\n",
      "          [ -7211, -13164,  -9601,  -3791,   1638,  -8856, -15507, -20934],\n",
      "          [ -9323, -18502, -26422, -21953, -11903,  -1869,   -770,    275],\n",
      "          [-22867, -25475, -24105, -18707,  -6642,   1836,   7508,   2200],\n",
      "          [ -6349,  -5193,   3702,   7331,   1323,  -2795,  -5631,  -1756]],\n",
      "\n",
      "         [[ -1665,  -8093, -15514, -15085, -16434, -14235,  -7570,  -3864],\n",
      "          [  9178,  13416,  -3077,  -9471,  -8265,  -3797,   6068,   8108],\n",
      "          [  5911,  19023,   8255, -12406, -19754, -15241,  -6572,  -4430],\n",
      "          [ -4403,   4000,  13434,  -1408, -22873, -29849, -20747,  -7348],\n",
      "          [ -7463,  -8294,   4067,  23479,  18634,  -4044, -22803, -19196],\n",
      "          [ -3251,  -6948,  -5594,  11935,  31161,  14729, -10344, -15991],\n",
      "          [ -3833,  -3925, -11491, -15409,  -5872,   1366,   2716,  -1134],\n",
      "          [ -9553, -12773, -11298, -13131, -10827,  -4213,   3845,   1896]]]],\n",
      "       dtype=torch.int32)\n",
      "tensor([[[[ 6654,  4241,    99, 17356],\n",
      "          [13935, 16190,  7087,     0],\n",
      "          [    0,  1019,  2158,  2772],\n",
      "          [    0,     0,  4357,  5115]],\n",
      "\n",
      "         [[    0,     0,     0,     0],\n",
      "          [10621,     0, 11692, 11628],\n",
      "          [13010, 25040,     0,  3858],\n",
      "          [17375, 11829,     0,     0]],\n",
      "\n",
      "         [[ 2721,     0,     0,     0],\n",
      "          [ 5420,  1968,     0,     0],\n",
      "          [ 6916,  1332,     0,     0],\n",
      "          [    0,  5025,     0,     0]],\n",
      "\n",
      "         [[    0,     0,     0,     0],\n",
      "          [ 1463,     0, 18595, 16935],\n",
      "          [ 8371,     0,     0,  2962],\n",
      "          [    0,     0,     0,  1684]],\n",
      "\n",
      "         [[ 7378,  2497, 14275, 17626],\n",
      "          [ 2047,     0,     0,     0],\n",
      "          [    0,     0,     0,     0],\n",
      "          [    0, 13229, 13905,     0]],\n",
      "\n",
      "         [[14677, 19352,  5056,     0],\n",
      "          [    0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0],\n",
      "          [21725, 20178,     0,     0]],\n",
      "\n",
      "         [[    0,     0, 17111,  7556],\n",
      "          [    0,     0,  7187, 20866],\n",
      "          [    0,     0,     0,  1306],\n",
      "          [ 9683,     0,     0,     0]],\n",
      "\n",
      "         [[16093, 19238,  1682,     0],\n",
      "          [    0,     0, 12043, 12307],\n",
      "          [    0,     0,     0,     0],\n",
      "          [14651,  5353,  1772,     0]],\n",
      "\n",
      "         [[    0,     0,     0,     0],\n",
      "          [ 4053,     0,     0,     0],\n",
      "          [ 7178,  3882,  6118, 20675],\n",
      "          [    0,   715,     0,     0]],\n",
      "\n",
      "         [[    0, 11021, 19773, 22526],\n",
      "          [    0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0],\n",
      "          [    0,     0, 12445, 19361]],\n",
      "\n",
      "         [[16583, 13252, 21707, 14012],\n",
      "          [ 4011,  5203,     0,     0],\n",
      "          [    0,     0,  1638,   275],\n",
      "          [    0,  7331,  1836,  7508]],\n",
      "\n",
      "         [[13416,     0,     0,  8108],\n",
      "          [19023, 13434,     0,     0],\n",
      "          [    0, 23479, 31161,     0],\n",
      "          [    0,     0,  1366,  3845]]]], dtype=torch.int32)\n",
      "tensor([[ 6654,  4241,    99, 17356, 13935, 16190,  7087,     0,     0,  1019,\n",
      "          2158,  2772,     0,     0,  4357,  5115,     0,     0,     0,     0,\n",
      "         10621,     0, 11692, 11628, 13010, 25040,     0,  3858, 17375, 11829,\n",
      "             0,     0,  2721,     0,     0,     0,  5420,  1968,     0,     0,\n",
      "          6916,  1332,     0,     0,     0,  5025,     0,     0,     0,     0,\n",
      "             0,     0,  1463,     0, 18595, 16935,  8371,     0,     0,  2962,\n",
      "             0,     0,     0,  1684,  7378,  2497, 14275, 17626,  2047,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0, 13229, 13905,     0,\n",
      "         14677, 19352,  5056,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0, 21725, 20178,     0,     0,     0,     0, 17111,  7556,\n",
      "             0,     0,  7187, 20866,     0,     0,     0,  1306,  9683,     0,\n",
      "             0,     0, 16093, 19238,  1682,     0,     0,     0, 12043, 12307,\n",
      "             0,     0,     0,     0, 14651,  5353,  1772,     0,     0,     0,\n",
      "             0,     0,  4053,     0,     0,     0,  7178,  3882,  6118, 20675,\n",
      "             0,   715,     0,     0,     0, 11021, 19773, 22526,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0, 12445, 19361,\n",
      "         16583, 13252, 21707, 14012,  4011,  5203,     0,     0,     0,     0,\n",
      "          1638,   275,     0,  7331,  1836,  7508, 13416,     0,     0,  8108,\n",
      "         19023, 13434,     0,     0,     0, 23479, 31161,     0,     0,     0,\n",
      "          1366,  3845]], dtype=torch.int32)\n",
      "tensor([ 1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
      "        -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "         1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "        -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
      "        -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-221848, -199346, -121240,  118808,  -75610,  274446, -111906,  -11862,\n",
      "           18224,  -29588]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "class watch_scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = scale_Bconvd(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = scale_Blinear(12*4*4, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = scale_Blinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = scale_Blinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(self.conv1.weight)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        print(self.conv2.weight)\n",
    "        print(x.int())\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.int())\n",
    "        print(self.fc1.weight[0])\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = watch_scale_leNet()\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "image, label = train_dataset[0]\n",
    "image = image*255\n",
    "image = image.unsqueeze(0)\n",
    "output = net(image)\n",
    "print(output.int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,     0,    -3,   -21,\n",
      "             -33,   -15,  -105,  -208,  -149,    79,   245,   -84,  -135,    73,\n",
      "             541,   629,   374,   127],\n",
      "          [    0,     0,     0,     0,   -30,   -66,  -100,  -182,  -167,  -154,\n",
      "             -85,    92,   101,   297,   404,   791,   603,   403,   588,   975,\n",
      "            1421,  1130,   633,   191],\n",
      "          [    0,     0,     0,   -49,  -317,  -448,  -247,    40,   385,   475,\n",
      "             710,   887,  1112,  1330,  1675,  1875,  1712,  1707,  1728,  1800,\n",
      "            1726,  1225,   672,   191],\n",
      "          [    0,     0,     0,   -67,  -396,  -354,   178,   838,  1450,  1734,\n",
      "            1988,  2200,  2285,  2127,  2417,  2165,  1944,  1590,   986,   618,\n",
      "             136,   -33,   -76,   -63],\n",
      "          [    0,     0,     0,    31,    36,   294,   875,  1406,  1665,  1860,\n",
      "            2019,  2106,  1471,   846,   611,   506,   167,  -460, -1214, -1360,\n",
      "           -1372, -1035,  -594,  -191],\n",
      "          [    0,     0,     0,    67,   316,   300,   410,    91,   -46,   189,\n",
      "             652,   516,   -39,  -710, -1078, -1057, -1068, -1202, -1361, -1185,\n",
      "            -931,  -596,  -298,   -64],\n",
      "          [    0,     0,     0,   -31,    -6,  -302,  -674, -1218, -1602, -1022,\n",
      "            -552,  -241,  -604, -1207, -1761, -1405, -1052,  -651,  -352,  -259,\n",
      "            -177,   -95,   -39,     0],\n",
      "          [    0,     0,     0,   -18,  -157,  -400,  -857, -1067, -1467, -1547,\n",
      "           -1061,  -396,  -258,  -621, -1004,  -867,  -685,  -395,     0,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,   -80,  -222,  -356,  -329,  -587, -1052,\n",
      "            -790,  -220,   336,   529,   356,    72,   -88,  -153,     0,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,   -14,   -15,   -19,  -142,  -547,\n",
      "            -824,  -628,    93,   976,  1164,   869,   506,   145,    25,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,  -128,  -178,  -335,\n",
      "            -671,  -610,  -262,   653,  1343,  1434,  1135,   575,   202,    27,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,   -11,  -166,  -167,\n",
      "            -299,  -448,  -370,  -208,   517,  1117,  1382,  1265,   642,   214,\n",
      "               0,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,     0,   -35,  -195,\n",
      "            -297,  -514,  -683, -1098,  -841,   124,  1151,  1664,  1158,   527,\n",
      "              64,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,     0,     0,   -81,\n",
      "            -322,  -593,  -963, -1325, -1014,  -305,   872,  1644,  1266,   682,\n",
      "              66,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,     0,     0,   -39,  -187,\n",
      "            -429,  -594,  -504,  -115,    98,   394,   815,  1093,   843,   490,\n",
      "              66,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,     0,     0,   -24,  -138,  -350,  -445,\n",
      "            -143,   405,   887,  1435,  1473,  1428,   896,   172,   -34,  -109,\n",
      "             -62,     0,     0,     0],\n",
      "          [    0,     0,     0,     0,   -23,   -89,  -280,  -467,  -248,   319,\n",
      "            1034,  1649,  2136,  2213,  1789,   894,  -156,  -564,  -518,  -340,\n",
      "             -66,     0,     0,     0],\n",
      "          [    0,     0,   -18,  -189,  -395,  -326,  -198,   324,   919,  1564,\n",
      "            2064,  2181,  1853,  1038,    58,  -778, -1221, -1119,  -816,  -391,\n",
      "              -2,     0,     0,     0],\n",
      "          [  -55,  -227,  -361,  -405,   -60,   389,   960,  1550,  1959,  2168,\n",
      "            1943,  1113,    70,  -865, -1497, -1686, -1387,  -962,  -510,  -182,\n",
      "               0,     0,     0,     0],\n",
      "          [ -191,  -506,  -351,   272,  1061,  1767,  2197,  2182,  1903,  1218,\n",
      "             239,  -714, -1428, -1701, -1483, -1057,  -615,  -281,   -78,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [  -81,   110,   607,  1248,  1649,  1749,  1249,   774,    98,  -678,\n",
      "           -1310, -1578, -1431, -1060,  -623,  -290,   -83,    -2,     0,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [  191,   506,   623,   506,   246,  -206,  -661, -1169, -1606, -1796,\n",
      "           -1527, -1162,  -681,  -295,   -89,    -9,     0,     0,     0,     0,\n",
      "               0,     0,     0,     0],\n",
      "          [   81,  -110,  -589, -1095, -1642, -1993, -1959, -1972, -1631, -1177,\n",
      "            -789,  -404,  -144,   -11,     0,     0,     0,     0,     0,     0,\n",
      "               0,     0,     0,     0]]]], dtype=torch.int32)\n",
      "tensor([[[[   0.,    0.,    0.,    0.,    0.,    0.,    0.,   79.,  245.,   73.,\n",
      "            629.,  374.],\n",
      "          [   0.,    0.,    0.,   40.,  475.,  887., 1330., 1875., 1712., 1800.,\n",
      "           1726.,  672.],\n",
      "          [   0.,   31.,  294., 1406., 1860., 2200., 2285., 2417., 1944.,  986.,\n",
      "            136.,    0.],\n",
      "          [   0.,   67.,  316.,  410.,  189.,  652.,    0.,    0.,    0.,    0.,\n",
      "              0.,    0.],\n",
      "          [   0.,    0.,    0.,    0.,    0.,    0.,  529.,  356.,    0.,    0.,\n",
      "              0.,    0.],\n",
      "          [   0.,    0.,    0.,    0.,    0.,    0.,  976., 1434., 1135.,  202.,\n",
      "              0.,    0.],\n",
      "          [   0.,    0.,    0.,    0.,    0.,    0.,    0., 1117., 1664., 1158.,\n",
      "             64.,    0.],\n",
      "          [   0.,    0.,    0.,    0.,    0.,    0.,    0.,  394., 1644., 1266.,\n",
      "             66.,    0.],\n",
      "          [   0.,    0.,    0.,    0.,  319., 1649., 2213., 1789.,  896.,    0.,\n",
      "              0.,    0.],\n",
      "          [   0.,    0.,  389., 1550., 2168., 2181., 1853.,   58.,    0.,    0.,\n",
      "              0.,    0.],\n",
      "          [ 110., 1248., 1767., 2197., 1903.,  239.,    0.,    0.,    0.,    0.,\n",
      "              0.,    0.],\n",
      "          [ 506.,  623.,  246.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "              0.,    0.]]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#对conv1的权重进行赋值\n",
    "weight_conv1 = torch.tensor([[-1,-1,-1,-1,-1],[-1,-1,-1,-1,1],[1,1,1,1,1],[1,1,1,1,-1],[1,1,1,-1,-1]])\n",
    "with torch.no_grad():\n",
    "    conv1.weight.copy_(weight_conv1)\n",
    "out1 = conv1(image)\n",
    "print(out1.int())\n",
    "out2 = relu1(out1)\n",
    "out3 = pool(out2)\n",
    "print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  2725,   1597,  -6894, -11001, -10972,  -8441,  -1208,    820],\n",
      "         [  1008,   6654,   2989,   4241,     99,  -2269,   8128,  17356],\n",
      "         [  -167,  13935,  16025,   7174,   3032, -12581, -15282,   -408],\n",
      "         [ -3023,   5814,  16190,  11842,   7087,  -9093, -28395, -20068],\n",
      "         [ -8031,  -7586,   1019,      1,   -442,   2158,    251,  -9298],\n",
      "         [-11323, -17918, -15966,  -6931,    263,  -1147,   2772,   -295],\n",
      "         [-23309, -23291, -23331, -14467,  -1684,  -7176,  -9618,   -374],\n",
      "         [-12255, -17007, -20372, -18343,  -7205,   4357,   5115,   4544]],\n",
      "\n",
      "        [[-21189, -29113, -27850, -33557, -34498, -34501, -28600, -25266],\n",
      "         [-17078, -29568, -26629, -12889,  -7589,  -9615,  -6798,  -5956],\n",
      "         [ 10621,  -1409,  -7479,  -3764,  11692,  10563,   4918,  -3382],\n",
      "         [  7255,   2280, -13660, -24750, -12857,    897,  10821,  11628],\n",
      "         [  3363,   6984,   5441,  -9525, -26232, -19164,  -6507,   3858],\n",
      "         [  5007,  13010,  25040,  22887,  -2779, -22203, -22470, -13607],\n",
      "         [ 16859,  17375,  11829,   7903,  -5098, -19246, -29468, -23762],\n",
      "         [  1749,  -8431, -17722, -19023, -14009,  -9875, -12613, -18288]],\n",
      "\n",
      "        [[  2087,   2721,  -5166, -10561, -19392, -22281, -20372, -15878],\n",
      "         [   530,   -604,  -9669, -18301, -26757, -31307, -22594, -13156],\n",
      "         [ -1853,  -1201,  -7969, -13084, -22452, -28991, -20368,  -6690],\n",
      "         [  1813,   5420,   1968, -12834, -16789, -16305, -13873, -13504],\n",
      "         [   563,   6916,  -2409, -12147, -11182, -13508, -12361, -17890],\n",
      "         [ -2751,   -284,   1332,  -4737,  -8777, -20783, -31756, -26777],\n",
      "         [ -2049,   -113,   5025,   2773, -10452, -29522, -37126, -22760],\n",
      "         [ -3789,  -9787, -10210, -10005, -14145, -19979, -22509, -13434]],\n",
      "\n",
      "        [[-16133, -19269, -22356, -26377, -29350, -33575, -30604, -30706],\n",
      "         [-17416, -25500, -27409, -23573, -19215, -19221, -14690, -10252],\n",
      "         [ -3165, -12063, -13745,  -2440,  12002,  18595,  13400,   5760],\n",
      "         [  1463,  -6730, -12092, -10118,   3623,  13363,  16935,   7386],\n",
      "         [  6137,   6378,  -5317, -14703, -24652, -20856,  -3649,   2962],\n",
      "         [  8371,   1178,  -7610, -17423, -24741, -23471, -15334,  -2393],\n",
      "         [ -2571, -10897, -14193, -12857, -19586, -21742, -15876,  -5726],\n",
      "         [-11237,  -9397, -15250, -24295, -29479, -28571, -14803,   1684]],\n",
      "\n",
      "        [[ -5097,  -3517,   -236,    737,   5846,  14275,  17406,  17626],\n",
      "         [  7378,   5402,   1429,   2497,     47,   3509,   4672,   7052],\n",
      "         [  2047,     51, -11155, -16654, -22554, -22767, -22182, -11588],\n",
      "         [ -1575,  -1092, -10448, -16612, -28153, -23899, -22635, -22830],\n",
      "         [ -4635,  -5680, -13723, -22843, -25736, -21050,  -3795,  -7992],\n",
      "         [-11851, -19976, -31926, -30493, -26849, -13283,  -4832,  -1887],\n",
      "         [-30391, -33949, -31029, -16427,  -1876,    700,  -1174,  -6388],\n",
      "         [-22779, -13401,    958,  13229,  13905,   3735,  -3657,  -8516]],\n",
      "\n",
      "        [[ 10775,  14677,  19352,  14895,   5056,  -5847, -16782, -24304],\n",
      "         [  3424,  -4076, -11487, -16845, -29817, -37863, -43130, -37888],\n",
      "         [-13491, -23821, -30483, -33658, -29580, -26925, -21126, -16856],\n",
      "         [-10349, -13968, -17986, -20618, -18779,  -5913,   -101,  -2834],\n",
      "         [ -6039, -14960, -17217, -17597, -13004,  -2390,  -4405,  -7404],\n",
      "         [ -7907, -17670, -20436, -14687,  -5469,  -1925, -10956, -24003],\n",
      "         [ -1949,   3555,   4427,   3219,  -1700, -18434, -34076, -30516],\n",
      "         [ 14211,  21725,  20178,  -2981, -32045, -45311, -40257, -19260]],\n",
      "\n",
      "        [[-10765, -17317, -26622, -26081, -11658, -18281, -12146,    532],\n",
      "         [ -7916,  -9408, -12195, -12823,   -255,  17111,   7556,   4430],\n",
      "         [ -5395, -13153, -13843, -24912, -17190,   7187,  16308,   7940],\n",
      "         [ -7187, -15626, -21796, -22468, -21577,  -9181,  12135,  20866],\n",
      "         [ -5673, -16082, -15441, -10497,  -4612,  -7960,  -9661,   1306],\n",
      "         [ -6591,  -4822,  -1870,  -5163, -11521, -20495, -20804, -13733],\n",
      "         [  7191,   9683,  -4583, -24361, -41978, -34588, -22214,  -8006],\n",
      "         [-11459, -19769, -26698, -27109, -18829,  -8411,  -2007,  -1450]],\n",
      "\n",
      "        [[ 10673,  16093,  19238,  13821,   1682, -11607, -19388, -21828],\n",
      "         [-16120, -21426, -23245, -35219, -41921, -52711, -48370, -35586],\n",
      "         [-15341, -21665, -21627, -20224, -14580, -15603, -14820, -12194],\n",
      "         [ -4905,  -9606,  -8326,   -558,   5127,  12043,  12307,   5564],\n",
      "         [ -5365,  -7350, -14135, -18827, -13842,  -5760,   -517,   -426],\n",
      "         [ -5337,  -6244,  -8804, -11895, -17577, -19399, -16248, -10707],\n",
      "         [  -733,  -2461,   2445,   5353,   1772,  -5688, -16146, -20064],\n",
      "         [ 14651,  13629,   3922,  -7181, -19763, -25889, -25809, -19568]],\n",
      "\n",
      "        [[ -5277,  -5627,  -1458,  -8639, -12300,  -4027,  -3518,  -3358],\n",
      "         [ -7564, -15058, -13169, -12379, -24897, -20181, -14064, -14188],\n",
      "         [   345, -12285, -20047, -14600, -24050, -28905, -28966, -12900],\n",
      "         [  4053,  -2328, -15112, -15960, -10733,  -1451,  -3857,  -4190],\n",
      "         [  4191,   4908,  -8973, -21479, -21096,   6118,  20675,  12008],\n",
      "         [   683,   7178,   3882,  -9473, -26045, -18861,   1032,  13855],\n",
      "         [   -29,  -1469,   -281,    715,  -9904, -21698, -14256,  -4494],\n",
      "         [ -7965, -12705, -11028,  -2907,   -917, -15611, -19519, -10024]],\n",
      "\n",
      "        [[-19363, -22129, -19616, -20049,  -9498,    949,  11824,  15850],\n",
      "         [ -4630,  -3526,   5563,  11021,  17499,  19773,  22526,  15050],\n",
      "         [  -869,  -6625,  -5685,  -5338,  -5920,  -4929,  -7308,  -6164],\n",
      "         [ -8075, -16184, -18520, -16832, -12837, -17915, -17575, -21104],\n",
      "         [ -8869, -20584, -28349, -23385, -14050,  -9230,  -4463, -15212],\n",
      "         [-15645, -26028, -34978, -33019, -28721, -21193,  -9978,  -1511],\n",
      "         [-29127, -37293, -45749, -49315, -32066,  -9174,   7452,   8554],\n",
      "         [-40579, -43859, -35494, -16301,  -2831,  12445,  19361,  15134]],\n",
      "\n",
      "        [[ 11871,  16583,  13252,  12247,  13098,  21707,  14012,  11390],\n",
      "         [ 13172,  15610,   4777,  -2595,  -5599,    353,     66,   -616],\n",
      "         [ -2165,   4011,   5203,  -5952, -15264, -23353, -18450, -10208],\n",
      "         [ -6801,  -4138,   5188,   1446,  -3995, -18409, -33747, -21796],\n",
      "         [ -7211, -13164,  -9601,  -3791,   1638,  -8856, -15507, -20934],\n",
      "         [ -9323, -18502, -26422, -21953, -11903,  -1869,   -770,    275],\n",
      "         [-22867, -25475, -24105, -18707,  -6642,   1836,   7508,   2200],\n",
      "         [ -6349,  -5193,   3702,   7331,   1323,  -2795,  -5631,  -1756]],\n",
      "\n",
      "        [[ -1665,  -8093, -15514, -15085, -16434, -14235,  -7570,  -3864],\n",
      "         [  9178,  13416,  -3077,  -9471,  -8265,  -3797,   6068,   8108],\n",
      "         [  5911,  19023,   8255, -12406, -19754, -15241,  -6572,  -4430],\n",
      "         [ -4403,   4000,  13434,  -1408, -22873, -29849, -20747,  -7348],\n",
      "         [ -7463,  -8294,   4067,  23479,  18634,  -4044, -22803, -19196],\n",
      "         [ -3251,  -6948,  -5594,  11935,  31161,  14729, -10344, -15991],\n",
      "         [ -3833,  -3925, -11491, -15409,  -5872,   1366,   2716,  -1134],\n",
      "         [ -9553, -12773, -11298, -13131, -10827,  -4213,   3845,   1896]]],\n",
      "       dtype=torch.int32)\n",
      "tensor([ 1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1, -1, -1,\n",
      "         1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1,  1,\n",
      "         1, -1, -1,  1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
      "        -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1,\n",
      "        -1,  1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
      "        -1,  1,  1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1,\n",
      "         1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1, -1,\n",
      "        -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
      "         1,  1, -1, -1,  1,  1, -1, -1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
      "        -1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1, -1], dtype=torch.int32)\n",
      "tensor([-221848], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "watch_conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "watch_conv1_weight = net.conv1.weight.int()\n",
    "watch_conv2 = nn.Conv2d(6, 12, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "watch_conv2_weight = net.conv2.weight.int()\n",
    "#print(watch_conv2_weight)\n",
    "#watch_conv2_weight = watch_conv2_weight\n",
    "#print(watch_conv2_weight)\n",
    "with torch.no_grad():\n",
    "    watch_conv1.weight.copy_(watch_conv1_weight)\n",
    "    watch_conv2.weight.copy_(watch_conv2_weight)\n",
    "image, label = train_dataset[0]\n",
    "image = 255*image\n",
    "\n",
    "out = watch_conv1(image)\n",
    "out = relu1(out)\n",
    "out = pool(out)\n",
    "out = watch_conv2(out)\n",
    "print(out.int())\n",
    "out = relu1(out)\n",
    "out = pool(out)\n",
    "out = out.view(-1)\n",
    "out_int = out.int()\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output5_txt.txt', 'w') as f:\n",
    "    for i in range(192):\n",
    "        value = out_int[i].item()\n",
    "        f.write(format(value, '032b') + '\\n')\n",
    "#将test_output5_txt.txt每格16行单独提取出来，放到不同的txt文件中\n",
    "with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output5_txt.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(12):\n",
    "        with open('/home/curry/code/curry_code_summay/rtl_works/BNN_on_fpga/test_output5_txt' + str(i) + '.txt', 'w') as f:\n",
    "            for j in range(16):\n",
    "                f.write(lines[i*16 + j])\n",
    "fc = nn.Linear(192, 1,bias=False)\n",
    "fc_weight = net.fc1.weight[0].int()\n",
    "print(fc_weight)\n",
    "with torch.no_grad():\n",
    "    fc.weight.copy_(fc_weight)\n",
    "out = fc(out)\n",
    "print(out.int())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SGMNET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
